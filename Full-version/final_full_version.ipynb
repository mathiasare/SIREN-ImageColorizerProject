{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "full_version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wMnYZyz1Ywh"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bEpLOl01Ywk"
      },
      "source": [
        "!pip install h5py==2.10.0\r\n",
        "#!pip install tensorflow==1.14.0\r\n",
        "!pip install keras==2.1.6\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYNKo8ckOmTE"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_bXVg6pH1Ywl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9380146a-e9ec-4bf6-b609-c0de45da8d02"
      },
      "source": [
        "import keras\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.preprocessing import image\n",
        "from keras.engine import Layer\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import RepeatVector, Permute\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NRex8pqI1Ywn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2ce81a-b27f-4772-dd1a-0c242c4d4e6e"
      },
      "source": [
        "\n",
        "#Load weights\n",
        "inception = InceptionResNetV2(weights='imagenet', include_top=True)\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "inception.graph = tf.get_default_graph()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "225214464/225209952 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3PJD5si1Ywn"
      },
      "source": [
        "# Get images\n",
        "\n",
        "\n",
        "def create_inception_embedding(grayscaled_rgb):\n",
        "    grayscaled_rgb_resized = []\n",
        "    for i in grayscaled_rgb:\n",
        "        i = resize(i, (299, 299, 3), mode='constant')\n",
        "        grayscaled_rgb_resized.append(i)\n",
        "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
        "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
        "    with inception.graph.as_default():\n",
        "        embed = inception.predict(grayscaled_rgb_resized)\n",
        "    return embed\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/ColabNotebooks/\n",
        "X = []\n",
        "for filename in os.listdir('Train/'):\n",
        "    X.append(img_to_array(load_img('Train/'+filename)))\n",
        "X = np.array(X, dtype=float)\n",
        "Xtrain = 1.0/255*X\n",
        "\n",
        "\n",
        "validation_data = []\n",
        "for filename in os.listdir('Valid/'):\n",
        "    validation_data.append(img_to_array(load_img('Valid/'+filename)))\n",
        "validation_data = np.array(validation_data, dtype=float)\n",
        "gray_me = gray2rgb(rgb2gray(1.0/255*validation_data))\n",
        "color_me_embed = create_inception_embedding(gray_me)\n",
        "color_me = rgb2lab(1.0/255*validation_data)[:,:,:,0]\n",
        "Y_batch = rgb2lab(1.0/255*validation_data)[:,:,:,1:] / 128\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n",
        "V = ([color_me, color_me_embed], Y_batch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6tEp5U61Ywo"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def siren_in(x):\n",
        "    x *= 1/30\n",
        "    return tf.math.sin(x)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubNbxwRU1Ywo"
      },
      "source": [
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "get_custom_objects().update({'siren_in': Activation(siren_in)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xal8i1q71Ywp"
      },
      "source": [
        "embed_input = Input(shape=(1000,))\n",
        "\n",
        "#Encoder\n",
        "encoder_input = Input(shape=(256, 256, 1,))\n",
        "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "\n",
        "#Fusion\n",
        "fusion_output = RepeatVector(32 * 32)(embed_input) \n",
        "fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
        "fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
        "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n",
        "\n",
        "#Decoder\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI0_mZ7A1Ywq"
      },
      "source": [
        "embed_input = Input(shape=(1000,))\n",
        "\n",
        "#Encoder\n",
        "encoder_input = Input(shape=(256, 256, 1,))\n",
        "encoder_output = Conv2D(64, (3,3), activation=\"siren_in\", kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1, maxval=1), padding='same', strides=2)(encoder_input)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3),  activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3),  activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3),  activation='relu', padding='same')(encoder_output)\n",
        "\n",
        "#Fusion\n",
        "fusion_output = RepeatVector(32 * 32)(embed_input) \n",
        "fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
        "fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
        "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n",
        "\n",
        "#Decoder\n",
        "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3),activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_2_we9u1Ywq"
      },
      "source": [
        "embed_input = Input(shape=(1000,))\n",
        "#activation=\"siren_in\", kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1, maxval=1)\n",
        "#Encoder\n",
        "encoder_input = Input(shape=(256, 256, 1,))\n",
        "encoder_output = Conv2D(64, (3,3), activation=\"siren_in\", kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1, maxval=1), padding='same', strides=2)(encoder_input)\n",
        "encoder_output = Conv2D(128, (3,3), activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(128, (3,3), activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(encoder_output)\n",
        "\n",
        "#Fusion\n",
        "fusion_output = RepeatVector(32 * 32)(embed_input) \n",
        "fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
        "fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
        "fusion_output = Conv2D(256, (1, 1),activation=tf.math.sin, kernel_initializer=\"he_uniform\",  padding='same')(fusion_output) \n",
        "\n",
        "#Decoder\n",
        "decoder_output = Conv2D(128, (3,3), activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(fusion_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3,3),activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3,3),activation=tf.math.sin, kernel_initializer=\"he_uniform\",padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(16, (3,3), activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3),activation=tf.math.sin, kernel_initializer=\"he_uniform\", padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXMUXfWe1Yws"
      },
      "source": [
        "from keras.callbacks import History\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "\n",
        "class SensitivitySpecificityCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % 100 == 1:\n",
        "            color_me = []\n",
        "            for filename in os.listdir('Test/'):\n",
        "                color_me.append(img_to_array(load_img('Test/'+filename )))\n",
        "            color_me = np.array(color_me, dtype=float)\n",
        "            gray_me = gray2rgb(rgb2gray(1.0/255*color_me))\n",
        "            color_me_embed = create_inception_embedding(gray_me)\n",
        "            color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
        "            color_me = color_me.reshape(color_me.shape+(1,))\n",
        "\n",
        "\n",
        "            # Test model\n",
        "            output = self.model.predict([color_me, color_me_embed])\n",
        "            output = output * 128\n",
        "\n",
        "            # Output colorizations\n",
        "            for i in range(len(output)):\n",
        "                cur = np.zeros((256, 256, 3))\n",
        "                cur[:,:,0] = color_me[i][:,:,0]\n",
        "                cur[:,:,1:] = output[i]\n",
        "                imsave(\"result/img_\"+str(i)+ str(epoch) +\".png\", lab2rgb(cur))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lhPJtn9g1Ywt"
      },
      "source": [
        "from keras.callbacks import History \n",
        "\n",
        "history = History()\n",
        "\n",
        "\n",
        "# Image transformer\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "#Generate training data\n",
        "batch_size = 50\n",
        "\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
        "        embed = create_inception_embedding(grayscaled_rgb)\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield ([X_batch, create_inception_embedding(grayscaled_rgb)], Y_batch)\n",
        "        \n",
        "model.compile(optimizer='Adam', loss=\"mse\") #metrics=['accuracy']\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit_generator(image_a_b_gen(batch_size), epochs=1400, validation_data=V,\n",
        "                    steps_per_epoch=3, callbacks=[SensitivitySpecificityCallback(), history])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-F5SuHE1Ywv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.arange(50,1200),history.history[\"loss\"][50:1200], \"purple\", label=\"loss\")\n",
        "plt.plot(np.arange(50,1200),history.history[\"val_loss\"][50:1200], \"brown\", label=\"val_loss\")\n",
        "plt.title(\"Relu loss and validation loss over epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.xlabel(\"epoch (3 steps/epoch)\")\n",
        "plt.legend()\n",
        "\n",
        "np.min(history.history[\"loss\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E--2LhvX1Ywv"
      },
      "source": [
        "plt.plot(np.arange(50,150),history.history[\"loss\"][50:150], \"y\")\n",
        "plt.plot(np.arange(50,150),history.history[\"val_loss\"][50:150], \"pink\")\n",
        "plt.title(\"Siren loss and validation loss over epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.xlabel(\"epoch (2 steps/epoch)\")\n",
        "\n",
        "np.min(history.history[\"loss\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dqs5_JV1Yww"
      },
      "source": [
        "color_me = []\n",
        "for filename in os.listdir('other/garde/'):\n",
        "    color_me.append(img_to_array(load_img('other/garde/'+ filename)))\n",
        "color_me = np.array(color_me, dtype=float)\n",
        "gray_me = gray2rgb(rgb2gray(1.0/255*color_me))\n",
        "color_me_embed = create_inception_embedding(gray_me)\n",
        "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n",
        "\n",
        "\n",
        "# Test model\n",
        "output = model.predict([color_me, color_me_embed])\n",
        "output = output * 128\n",
        "\n",
        "# Output colorizations\n",
        "for i in range(len(output)):\n",
        "    cur = np.zeros((256, 256, 3))\n",
        "    cur[:,:,0] = color_me[i][:,:,0]\n",
        "    cur[:,:,1:] = output[i]\n",
        "    imsave(\"result_z/ima_garde\"+str(i)+\".png\", lab2rgb(cur))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}